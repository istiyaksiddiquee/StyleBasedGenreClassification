{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import nltk \n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "with open(\"input.txt\", 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(100000))\n",
    "    \n",
    "input_file = open(\"input.txt\", \"r\", encoding=result.get(\"encoding\"))\n",
    "input_text = input_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = parse_text(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(input_text): \n",
    "\n",
    "    regex = r\"\\w+(?:[-'’]\\w+)*|'|[-.(]+|\\S\\w*\"\n",
    "    parsed_strings = re.findall(regex, input_text)\n",
    "    return_list = [re.sub('[^A-Za-z0-9]+', '', item) for item in parsed_strings if len(re.sub('[^A-Za-z0-9]+', '', item)) != 0 and item not in string.punctuation+''.join(['’', '”', '“', '”'])   and not item.isnumeric()]\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grammatical_counts(tokens):\n",
    "    \n",
    "    downtoners_list = ['almost', 'barely', 'hardly', 'merely', 'mildly', 'nearly', 'only', 'partially', 'partly', 'practically', 'scarcely', 'slightly', 'somewhat']\n",
    "\n",
    "    amplifier_list = ['absolutely', 'altogether', 'completely', 'enormously', 'entirely', 'extremely', 'fully', 'greatly', 'highly', 'intensely', 'perfectly', 'strongly', 'thoroughly', 'totally', 'utterly', 'very']\n",
    "\n",
    "    demostrative_list = ['this', 'that', 'these', 'those']\n",
    "\n",
    "    article_list = ['a', 'an', 'the']\n",
    "\n",
    "    # tokens = parse_text(input_text)\n",
    "    tags = nltk.pos_tag(tokens=tokens)\n",
    "    pos_counts = Counter(tag for _, tag in tags)    \n",
    "\n",
    "    noun_count = 0\n",
    "    verb_count = 0\n",
    "    adverb_count = 0\n",
    "    preposition_count = 0\n",
    "    adjective_count = 0     \n",
    "    infinitive_gerund_count = 0\n",
    "    \n",
    "    article_count = 0 \n",
    "    downtoner_count = 0\n",
    "    amplifier_count = 0 \n",
    "    demonstrative_count = 0\n",
    "\n",
    "    for item in tokens:\n",
    "        if item in article_list: \n",
    "            article_count += 1\n",
    "        if item in downtoners_list: \n",
    "            downtoner_count += 1 \n",
    "        if item in amplifier_list: \n",
    "            amplifier_count += 1 \n",
    "        if item in demostrative_list: \n",
    "            demonstrative_count += 1        \n",
    "\n",
    "    if pos_counts.get('NN') != None: \n",
    "        noun_count += pos_counts.get('NN')\n",
    "    if pos_counts.get('NNS') != None: \n",
    "        noun_count += pos_counts.get('NNS')\n",
    "    if pos_counts.get('NNP') != None: \n",
    "        noun_count += pos_counts.get('NNP')\n",
    "    if pos_counts.get('NNPS') != None: \n",
    "        noun_count += pos_counts.get('NNPS')    \n",
    "    \n",
    "    if pos_counts.get('VB') != None: \n",
    "        verb_count += pos_counts.get('VB')    \n",
    "    if pos_counts.get('VBD') != None: \n",
    "        verb_count += pos_counts.get('VBD')    \n",
    "    if pos_counts.get('VBG') != None: \n",
    "        verb_count += pos_counts.get('VBG')\n",
    "        infinitive_gerund_count += pos_counts.get('VBG')\n",
    "    if pos_counts.get('VBN') != None: \n",
    "        verb_count += pos_counts.get('VBN')    \n",
    "    if pos_counts.get('VBP') != None: \n",
    "        verb_count += pos_counts.get('VBP')    \n",
    "    if pos_counts.get('VBZ') != None: \n",
    "        verb_count += pos_counts.get('VBZ')    \n",
    "\n",
    "    if pos_counts.get('RB') != None: \n",
    "        adverb_count += pos_counts.get('RB')    \n",
    "    if pos_counts.get('RBR') != None: \n",
    "        adverb_count += pos_counts.get('RBR')    \n",
    "    if pos_counts.get('RBS') != None: \n",
    "        adverb_count += pos_counts.get('RBS') \n",
    "\n",
    "    if pos_counts.get('IN') != None: \n",
    "        preposition_count += pos_counts.get('IN') \n",
    "\n",
    "    if pos_counts.get('JJ') != None: \n",
    "        adjective_count += pos_counts.get('JJ')    \n",
    "    if pos_counts.get('JJR') != None: \n",
    "        adjective_count += pos_counts.get('JJR')    \n",
    "    if pos_counts.get('JJS') != None: \n",
    "        adjective_count += pos_counts.get('JJS') \n",
    "    \n",
    "    return (noun_count, verb_count, adverb_count, preposition_count, adjective_count, article_count, infinitive_gerund_count, downtoner_count, amplifier_count, demonstrative_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_and_word_level_stats(input_text):\n",
    "\n",
    "    char_count = 0\n",
    "    long_word_count = 0\n",
    "\n",
    "    punctuation_set = set(string.punctuation)\n",
    "    punctuation_count = sum([1 for x in input_text if x in punctuation_set])\n",
    "\n",
    "    sentences = nltk.sent_tokenize(input_text)\n",
    "    sentence_count = len(sentences)\n",
    "\n",
    "    tokens = parse_text(input_text)\n",
    "    word_count = len(tokens)    \n",
    "\n",
    "    for word in tokens: \n",
    "        char_count += len(word)\n",
    "        if len(word) > 6: \n",
    "            long_word_count += 1        \n",
    "\n",
    "    noun_count, verb_count, adverb_count, preposition_count, adjective_count, article_count, infinitive_gerund_count, downtoner_count, amplifier_count, demonstrative_count = get_grammatical_counts(tokens)\n",
    "\n",
    "    # avg_sentence_length = round(float(total_words/sentence_count), 3)\n",
    "    # avg_char_per_word = round(float(char_count/total_words), 3)\n",
    "\n",
    "    return sentence_count, word_count, char_count, punctuation_count, long_word_count, noun_count, verb_count, adverb_count, preposition_count, adjective_count, article_count, infinitive_gerund_count, downtoner_count, amplifier_count, demonstrative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(12, 238, 1223, 33, 68, 74, 34, 13, 35, 31, 17, 7, 1, 0, 7)"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "get_sentence_and_word_level_stats(input_text)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python",
   "display_name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}